{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt87Ne-YzYEc"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n"
      ],
      "metadata": {
        "id": "S1a2rcmTz7wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "2oifLVhLz-De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download kapillondhe/american-sign-language"
      ],
      "metadata": {
        "id": "OugdAga9z_Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip american-sign-language.zip"
      ],
      "metadata": {
        "id": "7ozG0Tuj0EK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "I3BhJl-o0-2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "image_size = (400, 400)"
      ],
      "metadata": {
        "id": "JPNtDqk91XDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and validation images\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    'ASL_Dataset/Train',\n",
        "    validation_split=0.25,\n",
        "    subset='training',\n",
        "    seed=121,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_dataset = keras.utils.image_dataset_from_directory(\n",
        "    'ASL_Dataset/Train',\n",
        "    validation_split=0.25,\n",
        "    subset='validation',\n",
        "    seed=121,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "3pSdI2Jo_0G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing classes\n",
        "classes = train_dataset.class_names"
      ],
      "metadata": {
        "id": "j7gRxBaSArei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #data augmentation\n",
        "# AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "# validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "rXeDnXrvAwMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(400,\n",
        "                                  400,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.15),\n",
        "    layers.RandomZoom(0.15),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "3B1_h-RACtPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(classes)\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "r5yS2kZ5BPbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JE5f1w-CBR3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "O4va1E-kBwZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2),\n",
        "]"
      ],
      "metadata": {
        "id": "PfHYL1NKvCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=validation_dataset,\n",
        "  epochs=epochs,\n",
        "  callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "xuGrkSrAB124"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig(\"validation score.jpg\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ewty5-6zCHy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('asl_model_2_layer.h5')"
      ],
      "metadata": {
        "id": "jtvccWI6CTKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = '/content/ASL_Dataset/Test/M/3001.jpg'\n",
        "def predict_model(image_path):\n",
        "  img = tf.keras.utils.load_img(\n",
        "      image_path, target_size=(400, 400)\n",
        "  )\n",
        "  img_array = tf.keras.utils.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "VIdpk-Qca_0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "main_path = 'ASL_Dataset/Test'\n",
        "y_pred = []\n",
        "y_label = []\n",
        "for label in os.listdir(main_path):\n",
        "  parent_path = os.path.join(main_path, label)\n",
        "  for image in os.listdir(parent_path):\n",
        "    image_path = os.path.join(parent_path, image)\n",
        "    score = predict_model(image_path)\n",
        "    y_pred.append(classes[np.argmax(score)])\n",
        "    y_label.append(label)\n",
        "    print(\n",
        "      \"Predicted Label: {} with a {:.2f} percent confidence, Actual Label: {}\"\n",
        "      .format(classes[np.argmax(score)], 100 * np.max(score), label)\n",
        "    )"
      ],
      "metadata": {
        "id": "bPguMTCZbbEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e0EsFue8KI6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}